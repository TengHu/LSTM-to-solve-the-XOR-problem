{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI - Request for Research 2.0 (https://blog.openai.com/requests-for-research-2/)\n",
    "\n",
    "## Warmup\n",
    "\n",
    "   Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequenceâ€™s end. Test the two approaches below:\n",
    "\n",
    " *  Generate a dataset of random 100,000 binary strings of length 50. Train the LSTM; what performance do you get?\n",
    "\n",
    " *  Generate a dataset of random 100,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1195773f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import inspect\n",
    "import torch.utils.data as data_utils\n",
    "import pdb\n",
    "import random\n",
    "import utils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "torch.manual_seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Bits String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni, t = generate_binary(length=4, num=20,variable=True)\\nprint (rnn_utils.pad_packed_sequence(i, batch_first=True)[0])\\nprint (rnn_utils.pad_packed_sequence(i, batch_first=True)[1])\\nprint (rnn_utils.pad_packed_sequence(t, batch_first=True)[0])\\nprint (rnn_utils.pad_packed_sequence(t, batch_first=True)[1])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_binary(length=1, num=1, variable=False):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, num):\n",
    "        sum = 0\n",
    "        input = []\n",
    "        target = []\n",
    "        for j in range(0, length):\n",
    "            temp = random.randint(0, 1)\n",
    "            sum += temp\n",
    "            current_input = np.zeros(2)\n",
    "            current_input[temp] = 1\n",
    "            input.append(current_input)\n",
    "            target.append(sum % 2)\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "    inputs = torch.Tensor(inputs)\n",
    "    targets = torch.Tensor(targets).unsqueeze(2)\n",
    "    return inputs, targets\n",
    "    \n",
    "    \n",
    "def collate_generate(batchsize=2, is_variable_length=False):\n",
    "    def pad_collate(batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        length = len(data[0])\n",
    "        \n",
    "        lengths_vector = [random.randint(1,length) if is_variable_length else length for i in range(0, batchsize)]\n",
    "        lengths_vector.sort(reverse=True)\n",
    "        \n",
    "        data = rnn_utils.pack_padded_sequence(torch.stack(data), lengths_vector, batch_first=True)\n",
    "        target = rnn_utils.pack_padded_sequence(torch.stack(target), lengths_vector, batch_first=True)\n",
    "        return [data, target]\n",
    "    return pad_collate\n",
    "\n",
    "'''\n",
    "i, t = generate_binary(length=4, num=20,variable=True)\n",
    "print (rnn_utils.pad_packed_sequence(i, batch_first=True)[0])\n",
    "print (rnn_utils.pad_packed_sequence(i, batch_first=True)[1])\n",
    "print (rnn_utils.pad_packed_sequence(t, batch_first=True)[0])\n",
    "print (rnn_utils.pad_packed_sequence(t, batch_first=True)[1])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=feature_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True)\n",
    "        self.h2o = nn.Linear(hidden_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def unpacked(self, hidden):\n",
    "        if isinstance(hidden, torch.nn.utils.rnn.PackedSequence):\n",
    "            hidden, lengths_vector = rnn_utils.pad_packed_sequence(hidden, batch_first=True)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        h, h_and_c = self.rnn(inputs)\n",
    "        h = self.unpacked(h)\n",
    "        outputs = self.h2o(h)\n",
    "        return outputs, self.sig(outputs)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs, hiddens):\n",
    "        h, h_and_c = self.rnn(inputs, hiddens)\n",
    "        h = self.unpacked(h)\n",
    "        outputs = self.h2o(h)\n",
    "        return outputs, self.sig(outputs)\n",
    "    \n",
    "\n",
    "    def initRandomHidden(self, batch_size=1):\n",
    "        h = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        c = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        return [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with fixed length 50\n",
    " *  Generate a dataset of random 100,000 binary strings of length 50. Train the LSTM; what performance do you get?\n",
    "\n",
    "\n",
    "* batch size 20\n",
    "* Vanilla SGD with learning rate 1\n",
    "* Cross Entropy Loss\n",
    "* Achieve 100 % with 2 hidden units after ~2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 1, batch size 20\n",
      "epoch 1, batch 300, loss 0.6936256885528564\n",
      "epoch 1, batch 600, loss 0.6932411789894104\n",
      "epoch 1, batch 900, loss 0.693221390247345\n",
      "epoch 1, batch 1200, loss 0.693185031414032\n",
      "epoch 1, batch 1500, loss 0.6930814981460571\n",
      "epoch 1, batch 1800, loss 0.6930596828460693\n",
      "epoch 1, batch 2100, loss 0.6929906010627747\n",
      "epoch 1, batch 2400, loss 0.6930245161056519\n",
      "epoch 1, batch 2700, loss 0.6930193305015564\n",
      "epoch 1, batch 3000, loss 0.6930099725723267\n",
      "epoch 1, batch 3300, loss 0.6929218769073486\n",
      "epoch 1, batch 3600, loss 0.6928685307502747\n",
      "epoch 1, batch 3900, loss 0.6927436590194702\n",
      "epoch 1, batch 4200, loss 0.6927247047424316\n",
      "epoch 1, batch 4500, loss 0.6926406025886536\n",
      "epoch 1, batch 4800, loss 0.6924952864646912\n",
      "Accuracy: \n",
      "57.99999999999999 %\n",
      "epoch 2, batch 300, loss 0.6923717260360718\n",
      "epoch 2, batch 600, loss 0.69215989112854\n",
      "epoch 2, batch 900, loss 0.6919844746589661\n",
      "epoch 2, batch 1200, loss 0.6917996406555176\n",
      "epoch 2, batch 1500, loss 0.6915663480758667\n",
      "epoch 2, batch 1800, loss 0.6913398504257202\n",
      "epoch 2, batch 2100, loss 0.6911237835884094\n",
      "epoch 2, batch 2400, loss 0.6907633543014526\n",
      "epoch 2, batch 2700, loss 0.6905525922775269\n",
      "epoch 2, batch 3000, loss 0.6901968121528625\n",
      "epoch 2, batch 3300, loss 0.6898555755615234\n",
      "epoch 2, batch 3600, loss 0.6895565986633301\n",
      "epoch 2, batch 3900, loss 0.6892204880714417\n",
      "epoch 2, batch 4200, loss 0.6889378428459167\n",
      "epoch 2, batch 4500, loss 0.6886681318283081\n",
      "epoch 2, batch 4800, loss 0.6883864998817444\n",
      "Accuracy: \n",
      "48.0 %\n",
      "epoch 3, batch 300, loss 0.6879487633705139\n",
      "epoch 3, batch 600, loss 0.6876333355903625\n",
      "epoch 3, batch 900, loss 0.6874355673789978\n",
      "epoch 3, batch 1200, loss 0.6870281100273132\n",
      "epoch 3, batch 1500, loss 0.6867280602455139\n",
      "epoch 3, batch 1800, loss 0.6863637566566467\n",
      "epoch 3, batch 2100, loss 0.6861022710800171\n",
      "epoch 3, batch 2400, loss 0.6857252717018127\n",
      "epoch 3, batch 2700, loss 0.6855134963989258\n",
      "epoch 3, batch 3000, loss 0.6852520704269409\n",
      "epoch 3, batch 3300, loss 0.6849768161773682\n",
      "epoch 3, batch 3600, loss 0.6847855448722839\n",
      "epoch 3, batch 3900, loss 0.6846185922622681\n",
      "epoch 3, batch 4200, loss 0.6842959523200989\n",
      "epoch 3, batch 4500, loss 0.6840751767158508\n",
      "epoch 3, batch 4800, loss 0.6836704611778259\n",
      "Accuracy: \n",
      "43.0 %\n",
      "epoch 4, batch 300, loss 0.6829895377159119\n",
      "epoch 4, batch 600, loss 0.6823999285697937\n",
      "epoch 4, batch 900, loss 0.6811960935592651\n",
      "epoch 4, batch 1200, loss 0.6791784167289734\n",
      "epoch 4, batch 1500, loss 0.6765321493148804\n",
      "epoch 4, batch 1800, loss 0.6733999848365784\n",
      "epoch 4, batch 2100, loss 0.6683382391929626\n",
      "epoch 4, batch 2400, loss 0.6670224666595459\n",
      "epoch 4, batch 2700, loss 0.6919662952423096\n",
      "epoch 4, batch 3000, loss 0.6827704310417175\n",
      "epoch 4, batch 3300, loss 0.6814088225364685\n",
      "epoch 4, batch 3600, loss 0.6798439621925354\n",
      "epoch 4, batch 3900, loss 0.5446643829345703\n",
      "epoch 4, batch 4200, loss 0.0459655337035656\n",
      "epoch 4, batch 4500, loss 0.01710411347448826\n",
      "epoch 4, batch 4800, loss 0.01050970796495676\n",
      "Accuracy: \n",
      "100.0 %\n",
      "epoch 5, batch 300, loss 0.0063540260307490826\n",
      "Accuracy: \n",
      "100.0 %\n",
      "epoch 6, batch 300, loss 0.005124911665916443\n",
      "Accuracy: \n",
      "100.0 %\n",
      "#################################################################################################### \n",
      "TestSet Accuracy:\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "print_every = 300\n",
    "epochs = 6\n",
    "num_observation = 100000\n",
    "num_test_observation = 10000\n",
    "\n",
    "length = 50\n",
    "hidden_size = 2\n",
    "batch_size = 20\n",
    "\n",
    "model = LSTMModel(2, hidden_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def evaluate(model, num_samples=num_test_observation, is_variable_length=False):\n",
    "    accuracy = 0\n",
    "    inputs, targets = generate_binary(length=length, num=num_samples)\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "    \n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_generate(batchsize=batch_size, is_variable_length=is_variable_length),\n",
    "        pin_memory=True)\n",
    "\n",
    "    \n",
    "    for batch_idx, data in enumerate(dataloader, 1):\n",
    "        hiddens = model.initRandomHidden(batch_size=batch_size)\n",
    "        input, targets = data\n",
    "        _, predicts = model(input, hiddens)\n",
    "\n",
    "        # unpack targets PackedSequence to get  variable length vector\n",
    "        targets, lengths_vector = rnn_utils.pad_packed_sequence(targets, batch_first=True)\n",
    "    \n",
    "        # we only care the final output of each string which is at index i-1 for i in lengths_vector\n",
    "        for idx_in_batch, idx_in_sequence in enumerate(lengths_vector.tolist(), 0):\n",
    "            #pdb.set_trace()\n",
    "            accuracy += ((predicts[idx_in_batch, idx_in_sequence-1] > 0.5).numpy() ==  targets[idx_in_batch, idx_in_sequence-1].numpy())\n",
    "        \n",
    "    print (accuracy[0] / num_samples * 100, \"%\")\n",
    "\n",
    "'''\n",
    "Training\n",
    "'''\n",
    "inputs, targets = generate_binary(length=length, num=num_observation)\n",
    "dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "\n",
    "\n",
    "for i in range(0, 1):\n",
    "    lr = 1\n",
    "    losses = []\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=1,\n",
    "                    drop_last=True,\n",
    "                    collate_fn=collate_generate(batchsize=batch_size,  is_variable_length=False),\n",
    "                    pin_memory=True)\n",
    "\n",
    "    print (\"learning rate {}, batch size {}\".format(lr, batch_size))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for i in range(1, epochs+1):    \n",
    "        running_loss = 0\n",
    "        for batch_idx, data in enumerate(dataloader, 1):\n",
    "            hiddens = model.initRandomHidden(batch_size=batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            input, targets = data\n",
    "            \n",
    "            outputs, _ = model(input, hiddens)\n",
    "            \n",
    "            # unpack targets PackedSequence to get  variable length vector\n",
    "            _, lengths_vector = rnn_utils.pad_packed_sequence(targets, batch_first=True)\n",
    "    \n",
    "            # use pack_padded_sequence function to flatten output according to variable length vector\n",
    "            outputs = rnn_utils.pack_padded_sequence(outputs, lengths_vector, batch_first=True)\n",
    "    \n",
    "            \n",
    "            loss = criterion(outputs.data, targets.data)\n",
    "            losses.append(loss)\n",
    "            running_loss += loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            if batch_idx % print_every == 0:\n",
    "                print (\"epoch {}, batch {}, loss {}\".format(i, batch_idx, running_loss / print_every))\n",
    "                if running_loss / print_every < 1e-2:\n",
    "                    break\n",
    "                running_loss = 0\n",
    "        print (\"Accuracy: \")\n",
    "        evaluate(model, num_samples=100, is_variable_length=True)\n",
    "        \n",
    "print ('#' * 100, '\\nTestSet Accuracy:')\n",
    "evaluate(model, num_samples=num_test_observation, is_variable_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fixed_test_fixed_loss = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x126e4d748>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b692630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with variable length in [1,50]\n",
    "\n",
    "* batch size 20\n",
    "* Vanilla SGD with learning rate 1\n",
    "* Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "\n",
    "# expect to be easy, because simple model can achieve this,  hidden size 1\n",
    "\n",
    "\n",
    "\n",
    "# visualization and animation\n",
    "\n",
    "# curriculum learning + analyze Loss \n",
    "\n",
    "# finish Repo \n",
    "\n",
    "# OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
